{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the credit data\n",
    "Columns we are keeping:\n",
    "\n",
    "- userID: unique respondent in-survey identification number used to match respondents between different surveys\n",
    "\n",
    "- date: data survey was conducted (2013 - 2024)\n",
    "\n",
    "- N1_3: whether they possess student loan or not (1 for possess)\n",
    "\n",
    "- N1_4: whether they possess home-based loan or not (1 for possess)\n",
    "\n",
    "- N1_5: whether they possess auto-based loan or not (1 for possess)\n",
    "\n",
    "- N1_6: whether they possess other personal loan or not (1 for possess)\n",
    "\n",
    "- N2_1: current balance of credit card loans\n",
    "\n",
    "- N2_3: current balance of student loans\n",
    "\n",
    "- N10_7: Dollar amount granted by lender for student loan\n",
    "\n",
    "- N15: Loan payments late by more than 30 days in past 12 months (1 for late payment)\n",
    "\n",
    "- N16: Loan payments late by more than 90 days in past 12 months (1 for late payment)\n",
    "\n",
    "- N17a_5: How likely will request credit card limit increase in next 12 months\n",
    "\n",
    "- N22: Credit score (1 for below 620; 2 for 620 - 679; 3 for 680 - 719; 4 for 720 - 760; 5 for Above 760; 6 for don't know)\n",
    "\n",
    "- N23: Last time checked credit score (1 for <1 mon; 2 for between 1 - 6 mon ago; 3 for 6-12 mon ago; 4 for 1-2 yrs ago; 5 for >2yrs ago; 6 for don't know)\n",
    "\n",
    "- N25: Likelihood of being able to come up with $2000 in the next month given an unexpected need (0-100 percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>N1_3</th>\n",
       "      <th>N1_4</th>\n",
       "      <th>N1_5</th>\n",
       "      <th>N1_6</th>\n",
       "      <th>N2_1</th>\n",
       "      <th>N2_3</th>\n",
       "      <th>N10_7</th>\n",
       "      <th>N15</th>\n",
       "      <th>N16</th>\n",
       "      <th>N17a_5</th>\n",
       "      <th>N22</th>\n",
       "      <th>N23</th>\n",
       "      <th>N25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000337</td>\n",
       "      <td>201310</td>\n",
       "      <td>5.382000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000341</td>\n",
       "      <td>201310</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70003202</td>\n",
       "      <td>201310</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70003205</td>\n",
       "      <td>201310</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003238</td>\n",
       "      <td>201310</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34357</th>\n",
       "      <td>75017565</td>\n",
       "      <td>202402</td>\n",
       "      <td>0.741707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34358</th>\n",
       "      <td>75017580</td>\n",
       "      <td>202402</td>\n",
       "      <td>1.262060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34359</th>\n",
       "      <td>75017584</td>\n",
       "      <td>202402</td>\n",
       "      <td>1.467306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34360</th>\n",
       "      <td>75017586</td>\n",
       "      <td>202402</td>\n",
       "      <td>0.545003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34361</th>\n",
       "      <td>75017613</td>\n",
       "      <td>202402</td>\n",
       "      <td>0.382379</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34362 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userid    date    weight  N1_3  N1_4  N1_5  N1_6     N2_1     N2_3  \\\n",
       "0      70000337  201310  5.382000     1     0     0     0      NaN   3600.0   \n",
       "1      70000341  201310  0.557000     1     0     1     0  20000.0  10000.0   \n",
       "2      70003202  201310  0.868000     0     0     0     0      NaN      NaN   \n",
       "3      70003205  201310  0.422000     0     0     0     0  70000.0      NaN   \n",
       "4      70003238  201310  0.638000     0     0     0     0      NaN      NaN   \n",
       "...         ...     ...       ...   ...   ...   ...   ...      ...      ...   \n",
       "34357  75017565  202402  0.741707     1     1     1     0    250.0  50000.0   \n",
       "34358  75017580  202402  1.262060     0     0     0     0   8000.0      NaN   \n",
       "34359  75017584  202402  1.467306     1     0     1     0  10000.0  18000.0   \n",
       "34360  75017586  202402  0.545003     1     0     0     0  19000.0  52000.0   \n",
       "34361  75017613  202402  0.382379     1     0     1     0      NaN  95000.0   \n",
       "\n",
       "       N10_7  N15  N16  N17a_5  N22  N23    N25  \n",
       "0        NaN  1.0  NaN     NaN  NaN  NaN    NaN  \n",
       "1        NaN  0.0  NaN     NaN  NaN  NaN    NaN  \n",
       "2        NaN  0.0  NaN     NaN  NaN  NaN    NaN  \n",
       "3        NaN  0.0  NaN     NaN  NaN  NaN    NaN  \n",
       "4        NaN  0.0  NaN     NaN  NaN  NaN    NaN  \n",
       "...      ...  ...  ...     ...  ...  ...    ...  \n",
       "34357    NaN  0.0  NaN     2.0  4.0  4.0   93.0  \n",
       "34358    NaN  0.0  NaN     NaN  5.0  1.0  100.0  \n",
       "34359    NaN  0.0  NaN     NaN  1.0  1.0    0.0  \n",
       "34360    NaN  0.0  NaN     NaN  2.0  5.0  100.0  \n",
       "34361    NaN  0.0  NaN     NaN  5.0  1.0   99.0  \n",
       "\n",
       "[34362 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_df = pd.read_excel(\"potentialDataSetsHW2/sce_credit.xlsx\", sheet_name=\"Data\")\n",
    "reduced_credit_df = credit_df[[\"userid\", \"date\", \"weight\", \n",
    "                               \"N1_3\", \"N1_4\",\"N1_5\",\"N1_6\",\n",
    "                               \"N2_1\", \"N2_3\",\n",
    "                               \"N10_7\", \"N15\", \"N16\", \"N17a_5\",\n",
    "                               \"N22\", \"N23\", \"N25\"]]\n",
    "reduced_credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'date', 'weight', 'N1_3', 'N1_4', 'N1_5', 'N1_6', 'N2_1',\n",
       "       'N2_3', 'N10_7', 'N15', 'N16', 'N17a_5', 'N22', 'N23', 'N25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_credit_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_credit_df[\"year\"] = reduced_credit_df[\"date\"].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the housing spending data\n",
    "Columns we are keeping:\n",
    "\n",
    "- userID: unique respondent in-survey identification number used to match respondents between different surveys\n",
    "\n",
    "- date: data survey was conducted (2013 - 2024)\n",
    "\n",
    "- qsp3_1: home appliance purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_2: electronics, computers, or cell phone purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_3: furniture purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_4: home repairs, improvements or renovations purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_5: cars/vehicle purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_6: trip/vacation purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_9: house/apartment purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp3_8: no large purchase during last 4 months (only have data from 2015 and on; house option added only Aug 2016)\n",
    "\n",
    "- qsp5_1: proportion of current monthly salary on housing\n",
    "\n",
    "- qsp5_2: proportion of current monthly salary on utilities\n",
    "\n",
    "- qsp5_3: proportion of current monthly salary on food\n",
    "\n",
    "- qsp5_4: proportion of current monthly salary on clothing, footwear, personal care\n",
    "\n",
    "- qsp5_6: proportion of current monthly salary on transportion\n",
    "\n",
    "- qsp5_7: proportion of current monthly salary on medical care\n",
    "\n",
    "- qsp5_8: proportion of current monthly salary on education and child care\n",
    "\n",
    "- qsp5_9: proportion of current monthly salary on other (gifts, child support, charity, etc.)\n",
    "\n",
    "- qsp12_n: if get 10% more income, what they would do (3 for use all to pay debt; 5,6, 7 for use some to pay debt; 1, 2, 4 for use none for debt)\n",
    "\n",
    "- qsp15new: variability in household income month to month (1 for <5%; 2 for 5%-15%; 3 for >15%)\n",
    "\n",
    "- k2e: whether there exist a family budget (1 for yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hhspending_df = pd.read_excel(\"potentialDataSetsHW2/sce_household_spending.xlsx\", sheet_name=\"Data\")\\nreduced_hhspending_df = hhspending_df[[\"userid\", \"date\", \\n                                       \"qsp3_1\", \"qsp3_2\", \"qsp3_3\", \"qsp3_4\",\"qsp3_5\",\"qsp3_6\",\"qsp3_9\",\"qsp3_8\",\\n                                       \"qsp5_1\", \"qsp5_2\",\"qsp5_3\",\"qsp5_4\",\"qsp5_5\", \"qsp5_6\", \"qsp5_7\", \"qsp5_8\", \"qsp5_9\",\\n                                       \"qsp12n\", \"qsp15new\", \"k2e\"]]\\nreduced_hhspending_df '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" hhspending_df = pd.read_excel(\"potentialDataSetsHW2/sce_household_spending.xlsx\", sheet_name=\"Data\")\n",
    "reduced_hhspending_df = hhspending_df[[\"userid\", \"date\", \n",
    "                                       \"qsp3_1\", \"qsp3_2\", \"qsp3_3\", \"qsp3_4\",\"qsp3_5\",\"qsp3_6\",\"qsp3_9\",\"qsp3_8\",\n",
    "                                       \"qsp5_1\", \"qsp5_2\",\"qsp5_3\",\"qsp5_4\",\"qsp5_5\", \"qsp5_6\", \"qsp5_7\", \"qsp5_8\", \"qsp5_9\",\n",
    "                                       \"qsp12n\", \"qsp15new\", \"k2e\"]]\n",
    "reduced_hhspending_df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_hhspending_df[\"year\"] = reduced_hhspending_df[\"date\"].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Job and Income Data\n",
    "\n",
    "Columns we want to keep:\n",
    "\n",
    "- userid: Unique identifier\n",
    "\n",
    "- date: date survey was conducted (2014 and on)\n",
    "\n",
    "- l3: annual salary before tax and deductions (including bonuses, overtime, tips/commissions)\n",
    "\n",
    "- l7dk_1: never had a paying job (1 for never; empty for having a paying job)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' job_df = pd.read_excel(\"potentialDataSetsHW2/sce_labor.xlsx\", sheet_name=\"Data\")\\nreduced_labor_df = job_df[[\"userid\", \"date\", \\n                                       \"l3\", \"l7dk_1\"]]\\nreduced_labor_df '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" job_df = pd.read_excel(\"potentialDataSetsHW2/sce_labor.xlsx\", sheet_name=\"Data\")\n",
    "reduced_labor_df = job_df[[\"userid\", \"date\", \n",
    "                                       \"l3\", \"l7dk_1\"]]\n",
    "reduced_labor_df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_labor_df[\"year\"] = reduced_labor_df[\"date\"].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing household status\n",
    "\n",
    "Columns we want to keep:\n",
    "\n",
    "- userid\n",
    "\n",
    "- date\n",
    "\n",
    "- a1new: current living situation (1 for married; 2 for separated; 3 for divorced; 4 for widowed; 5 for never married)\n",
    "\n",
    "- b1_1: household income\n",
    "\n",
    "- b5_1: Percentage change in HH income last 12 mos. vs. previous year\n",
    "\n",
    "- i1_6: Disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hhfinance_df = pd.read_excel(\"potentialDataSetsHW2/sce_household_finance.xlsx\", sheet_name=\"Data\")\\nreduced_hhfinance_df = hhfinance_df[[\"userid\", \"date\", \\n                                       \"a1new\", \"b1_1\", \"b5_1\", \"i1_6\"]]\\nreduced_hhfinance_df '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" hhfinance_df = pd.read_excel(\"potentialDataSetsHW2/sce_household_finance.xlsx\", sheet_name=\"Data\")\n",
    "reduced_hhfinance_df = hhfinance_df[[\"userid\", \"date\", \n",
    "                                       \"a1new\", \"b1_1\", \"b5_1\", \"i1_6\"]]\n",
    "reduced_hhfinance_df \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_hhfinance_df[\"year\"] = reduced_hhfinance_df[\"date\"].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reduced_credit_df.set_index([\"userid\", \"date\"], inplace = True)\\nreduced_hhspending_df.set_index([\"userid\", \"date\"], inplace = True)\\nreduced_labor_df.set_index([\"userid\", \"date\"], inplace = True)\\nreduced_hhfinance_df.set_index([\"userid\", \"date\"], inplace = True) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" reduced_credit_df.set_index([\"userid\", \"date\"], inplace = True)\n",
    "reduced_hhspending_df.set_index([\"userid\", \"date\"], inplace = True)\n",
    "reduced_labor_df.set_index([\"userid\", \"date\"], inplace = True)\n",
    "reduced_hhfinance_df.set_index([\"userid\", \"date\"], inplace = True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' joined_df = reduced_credit_df.join(reduced_hhspending_df, how = \"inner\") '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" joined_df = reduced_credit_df.join(reduced_hhspending_df, how = \"inner\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' common_index = set(reduced_credit_df.index) &                set(reduced_hhfinance_df.index) \\n\\nprint(f\"Number of common (userid, date): {len(common_index)}\") '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" common_index = set(reduced_credit_df.index) & \\\n",
    "               set(reduced_hhfinance_df.index) \n",
    "\n",
    "print(f\"Number of common (userid, date): {len(common_index)}\") \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
